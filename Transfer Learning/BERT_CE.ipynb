{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuqvn01FO3SW",
        "outputId": "f2fcb0c4-6321-4efd-c8e6-d0d57e3a401d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-tiGmMwRyHH",
        "outputId": "4970ada6-46f7-4499-c90c-d2e386993c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines) (24.2.0)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9rKdPEKODeV"
      },
      "outputs": [],
      "source": [
        "from typing import Optional, Union\n",
        "from datasets import load_dataset\n",
        "from dataclasses import dataclass\n",
        "import evaluate\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, get_scheduler, AutoConfig, AutoModel\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "SEED = 595\n",
        "set_seed(595)\n"
      ],
      "metadata": {
        "id": "u368GdrGOUzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poes02H-SOoP",
        "outputId": "48cec71b-2bab-464e-d5fa-d79d598ff9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/EECS595/Project/Verifiable-Coherent-NLU-main'"
      ],
      "metadata": {
        "id": "yzma6z3sQLan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = os.path.join(\"drive\", \"My Drive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "sys.path.append(DRIVE_PATH)\n",
        "print(os.listdir(DRIVE_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8bE4PN6QP1a",
        "outputId": "3a9ed11f-97b9-43a3-a6c5-e5394f74d5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['README.md', 'requirements.txt', 'www', 'all_data', 'cache', 'saved_models', 'Verifiable-Coherent-NLU.ipynb', 'withBRET_CE.ipynb', 'project_fineTunePIQA.ipynb', 'BERT_CE.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pickle\n",
        "cache_train = os.path.join(DRIVE_PATH, 'all_data/ConvEnt/ConvEnt_train_resplit.json')\n",
        "cache_dev = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_dev_resplit.json')\n",
        "cache_test = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_test_resplit.json')\n",
        "ConvEnt_train = json.load(open(cache_train))\n",
        "ConvEnt_dev = json.load(open(cache_dev))\n",
        "ConvEnt_test = json.load(open(cache_test))\n",
        "\n",
        "# Combine train and dev and do cross-validation\n",
        "cache_folds = os.path.join(DRIVE_PATH,'all_data/ConvEnt/ConvEnt_folds.pkl') # Folds used for results presented in paper\n",
        "ConvEnt_train = ConvEnt_train + ConvEnt_dev\n",
        "train_sources = list(set([ex['dialog_source'] for ex in ConvEnt_train]))\n",
        "print(\"Reserved %s dialog sources for training and validation.\" % len(train_sources))\n",
        "\n",
        "no_folds = 8\n",
        "if not os.path.exists(cache_folds):\n",
        "  folds = []\n",
        "  for k in range(no_folds):\n",
        "    folds.append(np.random.choice(train_sources, size=5, replace=False))\n",
        "    train_sources = [s for s in train_sources if s not in folds[-1]]\n",
        "  assert len(train_sources) == 0\n",
        "  print(folds)\n",
        "  pickle.dump(folds, open(cache_folds, 'wb'))\n",
        "else:\n",
        "  folds = pickle.load(open(cache_folds, 'rb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM7qbGV0P5sM",
        "outputId": "3bd9d592-6c0c-4cf1-9317-2ee42610fd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reserved 40 dialog sources for training and validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mode = \"bert\"\n",
        "task_name = \"ce\""
      ],
      "metadata": {
        "id": "sCxtWHOfUGwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if task_name in ['trip', 'ce']:\n",
        "  multiple_choice = False\n",
        "elif task_name == 'art':\n",
        "  multiple_choice = True\n",
        "else:\n",
        "  raise ValueError(\"Task name should be set to 'trip', 'ce', or 'art' in the first cell of the notebook!\")\n",
        "\n",
        "if mode == 'bert':\n",
        "  model_name = 'bert-large-uncased'\n",
        "elif mode == 'roberta':\n",
        "  model_name = 'roberta-large'\n",
        "elif mode == 'roberta_mnli':\n",
        "  model_name = 'roberta-large-mnli'\n",
        "elif mode == 'deberta':\n",
        "  model_name = 'microsoft/deberta-base'\n",
        "elif mode == 'deberta_large':\n",
        "  model_name = 'microsoft/deberta-large'"
      ],
      "metadata": {
        "id": "5pAt0dYxUTcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, RobertaTokenizer, DebertaTokenizer, AlbertTokenizer, T5Tokenizer, GPT2Tokenizer\n",
        "\n",
        "#from DeBERTa import deberta\n",
        "if mode in ['bert']:\n",
        "  tokenizer_class = BertTokenizer\n",
        "elif mode in ['roberta', 'roberta_mnli']:\n",
        "  tokenizer_class = RobertaTokenizer\n",
        "elif mode in ['deberta', 'deberta_large']:\n",
        "  tokenizer_class = DebertaTokenizer\n",
        "\n",
        "tokenizer = tokenizer_class.from_pretrained(model_name,\n",
        "                                                do_lower_case = False,\n",
        "                                                cache_dir=os.path.join(DRIVE_PATH, 'cache'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXc1or22UC3f",
        "outputId": "58722818-f9e8-4800-b838-b647a6de7acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ConvEnt_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Me-LpyAcSjWl",
        "outputId": "63dd1728-07c8-4919-eff2-e08e41c106ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConvEnt_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjiyHl8RSrmD",
        "outputId": "1f050fc3-33a0-42c5-f008-9dd240fdb47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 15,\n",
              " 'dialog_source': 'SW2020',\n",
              " 'label': 1,\n",
              " 'type': 'belief',\n",
              " 'turns': [{'speaker': 'B',\n",
              "   'text': 'Hi, um, okay what, now, uh, what particularly, particularly what kind of music do you like?'},\n",
              "  {'speaker': 'A',\n",
              "   'text': \"Well, I mostly listen to popular music.  I, uh, listen to it all the time in, in my car, so, I, I tend to be one of those people who switches stations a lot because I don't like commercials.  But,\"},\n",
              "  {'speaker': 'B', 'text': 'Yeah.'},\n",
              "  {'speaker': 'A',\n",
              "   'text': \"uh, I find myself listening to popular music, and, uh, quite honestly, I, I have some little children and I, unfortunately, found myself listening to a lot of nursery rhyme music here lately, but that's not by my choice.\"}],\n",
              " 'hypothesis': 'SpeakerA likes popular music '}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConvEnt_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGthME-AiPx_",
        "outputId": "7cfe7a81-b8ce-4ef4-baa3-3a17ae40e7af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 73,\n",
              " 'dialog_source': 'SW2041',\n",
              " 'label': 0,\n",
              " 'type': 'fact',\n",
              " 'turns': [{'speaker': 'B',\n",
              "   'text': \"He's an aerobics instructor.  And, um, is going to be, uh, entering [breathing] North Texas [breathing] for uh, a Kinesiology program there.\"},\n",
              "  {'speaker': 'A', 'text': 'Uh-huh.'},\n",
              "  {'speaker': 'B',\n",
              "   'text': 'And, um, [breathing] the, the how I met him was through, uh, the aerobics class that he used to teach.'},\n",
              "  {'speaker': 'A', 'text': \"Uh-huh. You're a student?\"}],\n",
              " 'hypothesis': 'SpeakerA is a student of her husband'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConvEnt_dev[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBLbHpNSidaf",
        "outputId": "0b42dbe1-35e0-4905-8926-4d5dcaf77301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 169,\n",
              " 'dialog_source': 'SW2067',\n",
              " 'label': 0,\n",
              " 'type': 'belief',\n",
              " 'turns': [{'speaker': 'B',\n",
              "   'text': \"Um, I don't know if I'm really afraid of spending too much.  I just, uh, don't think that I need them, you know.  I, uh, they are tempting at times,\"},\n",
              "  {'speaker': 'A', 'text': '[Laughter].'},\n",
              "  {'speaker': 'B',\n",
              "   'text': \"but I, I just, you know, sometimes I just don't like everybody knowing everything about me, you know, so,\"}],\n",
              " 'hypothesis': \"SpeakerA doesn't like to use a credit card\"}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('train examples:', len(ConvEnt_train))\n",
        "print('dev examples:', len(ConvEnt_dev))\n",
        "print('test examples:', len(ConvEnt_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "550fLBInTDWC",
        "outputId": "80f7230f-f80a-4dc5-ab66-faa9f5b02087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train examples: 703\n",
            "dev examples: 110\n",
            "test examples: 172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "debug = False"
      ],
      "metadata": {
        "id": "ptDwoD3kUjC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from www.dataset.featurize import add_bert_features_ConvEnt, get_tensor_dataset\n",
        "import pickle\n",
        "seq_length = 128\n",
        "\n",
        "ConvEnt_train = add_bert_features_ConvEnt(ConvEnt_train, tokenizer, seq_length, add_segment_ids=True)\n",
        "ConvEnt_dev = add_bert_features_ConvEnt(ConvEnt_dev, tokenizer, seq_length, add_segment_ids=True)\n",
        "ConvEnt_test = add_bert_features_ConvEnt(ConvEnt_test, tokenizer, seq_length, add_segment_ids=True)\n",
        "\n",
        "ConvEnt_train_folds = [[] for _ in range(no_folds)]\n",
        "ConvEnt_dev_folds = [[] for _ in range(no_folds)]\n",
        "for k in range(no_folds):\n",
        "  ConvEnt_train_folds[k] = [ex for ex in ConvEnt_train if ex['dialog_source'] not in folds[k]]\n",
        "  ConvEnt_dev_folds[k] = [ex for ex in ConvEnt_train if ex['dialog_source'] in folds[k]]\n",
        "\n",
        "  if debug:\n",
        "    ConvEnt_train_folds[k] = ConvEnt_train_folds[k][:10]\n",
        "    ConvEnt_dev_folds[k] = ConvEnt_dev_folds[k][:10]\n",
        "\n",
        "if debug:\n",
        "  ConvEnt_train = ConvEnt_train[:10]\n",
        "  ConvEnt_dev = ConvEnt_dev[:10]\n",
        "  ConvEnt_test = ConvEnt_test[:10]\n",
        "\n",
        "ConvEnt_train_tensor = get_tensor_dataset(ConvEnt_train, label_key='label', add_segment_ids=True)\n",
        "ConvEnt_test_tensor = get_tensor_dataset(ConvEnt_test, label_key='label', add_segment_ids=True)\n",
        "\n",
        "# Training sets for each validation fold\n",
        "ConvEnt_train_folds_tensor = [get_tensor_dataset(ConvEnt_train_folds[k], label_key='label', add_segment_ids=True) for k in range(no_folds)]\n",
        "ConvEnt_dev_folds_tensor = [get_tensor_dataset(ConvEnt_dev_folds[k], label_key='label', add_segment_ids=True) for k in range(no_folds)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "collapsed": true,
        "id": "_SUapQ-wTMTN",
        "outputId": "fe3140d8-fc3d-4cc7-b0af-4b8ecdfcda63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-58e27c53e096>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mConvEnt_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_bert_features_ConvEnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvEnt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_segment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mConvEnt_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_bert_features_ConvEnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvEnt_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_segment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mConvEnt_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_bert_features_ConvEnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvEnt_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_segment_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, RobertaForSequenceClassification, DebertaForSequenceClassification, AlbertForSequenceClassification, AdamW\n",
        "from transformers import BertForMultipleChoice, RobertaForMultipleChoice, AlbertForMultipleChoice, DebertaModel\n",
        "from transformers import BertModel, RobertaModel, AlbertModel, DebertaModel, T5Model, T5EncoderModel, GPT2Model\n",
        "from transformers import RobertaForMaskedLM\n",
        "from transformers import BertConfig, RobertaConfig, DebertaConfig, AlbertConfig, T5Config, GPT2Config\n",
        "#from www.model.transformers_ext import DebertaForMultipleChoice\n",
        "from torch.optim import Adam\n",
        "if not multiple_choice:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForSequenceClassification\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel\n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForSequenceClassification\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForSequenceClassification\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel\n",
        "else:\n",
        "  if mode == 'bert':\n",
        "    model_class = BertForMultipleChoice\n",
        "    config_class = BertConfig\n",
        "    emb_class = BertModel\n",
        "  elif mode in ['roberta', 'roberta_mnli']:\n",
        "    model_class = RobertaForMultipleChoice\n",
        "    config_class = RobertaConfig\n",
        "    emb_class = RobertaModel\n",
        "    lm_class = RobertaForMaskedLM\n",
        "  elif mode in ['deberta', 'deberta_large']:\n",
        "    model_class = DebertaForMultipleChoice\n",
        "    config_class = DebertaConfig\n",
        "    emb_class = DebertaModel"
      ],
      "metadata": {
        "id": "_oeczcF5XJJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ConvEnt_train[0]['input_ids']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "collapsed": true,
        "id": "6DyrvTO5Utxm",
        "outputId": "fd1e9cb0-d37c-4c92-babf-8dd123949542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'input_ids'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-cccf38c5586a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mConvEnt_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'input_ids'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_batch_size = 1\n",
        "config_lr = 1e-5 # Selected learning rate for best RoBERTa-based model in TRIP paper\n",
        "config_epochs = 10"
      ],
      "metadata": {
        "id": "jJcDlEXzWk5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [config_batch_size]\n",
        "learning_rates = [config_lr]\n",
        "epochs = config_epochs\n",
        "eval_batch_size = 128"
      ],
      "metadata": {
        "id": "x3nUIuBrWVUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from www.model.train import train_epoch\n",
        "from www.model.eval import evaluate, save_results, save_preds\n",
        "from sklearn.metrics import accuracy_score\n",
        "from www.utils import print_dict, get_model_dir\n",
        "from collections import Counter\n",
        "\n",
        "seed_val = 22 # Save random seed for reproducibility\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "assert len(batch_sizes) == 1\n",
        "train_fold_sampler = [RandomSampler(f) for f in ConvEnt_train_folds_tensor]\n",
        "train_fold_dataloader = [DataLoader(f, sampler=train_fold_sampler[i], batch_size=batch_sizes[0]) for i, f in enumerate(ConvEnt_train_folds_tensor)]\n",
        "\n",
        "dev_fold_sampler = [SequentialSampler(f) for f in ConvEnt_dev_folds_tensor]\n",
        "dev_fold_dataloader = [DataLoader(f, sampler=dev_fold_sampler[i], batch_size=eval_batch_size) for i, f in enumerate(ConvEnt_dev_folds_tensor)]\n",
        "\n",
        "all_val_accs = Counter()\n",
        "print('Beginning grid search for ConvEnt over %s parameter combination(s)!' % (str(len(batch_sizes) * len(learning_rates))))\n",
        "for bs in batch_sizes:\n",
        "  for lr in learning_rates:\n",
        "    print('\\nTRAINING MODEL: bs=%s, lr=%s' % (str(bs), str(lr)))\n",
        "\n",
        "    for k in range(no_folds):\n",
        "      print('Beginning fold %s/%s...' % (str(k+1), str(no_folds)))\n",
        "\n",
        "      # Set up model\n",
        "      if 'mnli' not in mode:\n",
        "        model = model_class.from_pretrained(model_name,\n",
        "                                            cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "      else:\n",
        "        config = config_class.from_pretrained(model_name.replace('-mnli',''),\n",
        "                                        num_labels=3,\n",
        "                                        cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "        model = model_class.from_pretrained(model_name,\n",
        "                                            config=config,\n",
        "                                            cache_dir=os.path.join(DRIVE_PATH, 'cache'))\n",
        "        config.num_labels = 2\n",
        "        model.num_labels = 2\n",
        "        model.classifier = cls_head_class(config=config) # Need to bring in a classification head for only 2 labels\n",
        "\n",
        "      model.cuda()\n",
        "      device = model.device\n",
        "\n",
        "      # Set up optimizer\n",
        "      optimizer = AdamW(model.parameters(), lr=lr)\n",
        "      total_steps = len(train_fold_dataloader[k]) * epochs\n",
        "      scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps = total_steps)\n",
        "\n",
        "      for epoch in range(epochs):\n",
        "        # Train the model for one epoch\n",
        "        print('[%s] Beginning epoch...' % str(epoch))\n",
        "\n",
        "        epoch_loss, _ = train_epoch(model, optimizer, train_fold_dataloader[k], device, seg_mode=True if 'roberta' not in mode else False)\n",
        "\n",
        "        # Validate on dev set\n",
        "        results, _, _ = evaluate(model, dev_fold_dataloader[k], device, [(accuracy_score, 'accuracy')], seg_mode=True if 'roberta' not in mode else False)\n",
        "        print('[%s] Validation results:' % str(epoch))\n",
        "        print_dict(results)\n",
        "\n",
        "        # Save accuracy\n",
        "        acc = results['accuracy']\n",
        "        if (bs, lr, epoch) in all_val_accs:\n",
        "          all_val_accs[(bs, lr, epoch)] += acc\n",
        "        else:\n",
        "          all_val_accs[(bs, lr, epoch)] = acc\n",
        "\n",
        "      model.cpu()\n",
        "      del model\n",
        "      del optimizer\n",
        "      del results\n",
        "      del scheduler\n",
        "      del total_steps\n",
        "\n",
        "      print('[%s] Finished epoch.' % str(epoch))\n",
        "\n",
        "for k in all_val_accs:\n",
        "  all_val_accs[k] /= no_folds\n",
        "\n",
        "print('Top performing param combos:')\n",
        "print(all_val_accs.most_common(5))\n",
        "\n",
        "save_fname = os.path.join(DRIVE_PATH, 'saved_models/%s_ConvEnt_xval_%s.pkl' % (model_name.replace('/','-'), '_'.join([str(lr) for lr in learning_rates])))\n",
        "pickle.dump(all_val_accs, open(save_fname, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0o9_tZwW0WI",
        "outputId": "d2a57162-bbe6-445a-ca85-a76ddd1bf42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning grid search for ConvEnt over 1 parameter combination(s)!\n",
            "\n",
            "TRAINING MODEL: bs=1, lr=1e-05\n",
            "Beginning fold 1/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5416666666666666,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 2/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4603174603174603,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 3/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.49504950495049505,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 4/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5641025641025641,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4358974358974359,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4358974358974359,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 5/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5180722891566265,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4819277108433735,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 6/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.494949494949495,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.6262626262626263,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 7/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.4931506849315068,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:00s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5068493150684932,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Beginning fold 8/8...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[0] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[1] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[1] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[2] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[2] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.44545454545454544,\n",
            "}\n",
            "\n",
            "\n",
            "[3] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[3] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[4] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[4] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[5] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[5] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[6] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[6] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[7] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[7] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[8] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[8] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Beginning epoch...\n",
            "\tBeginning evaluation...\n",
            "\t\tRunning prediction...\n",
            "\t\tComputing metrics...\n",
            "\tFinished evaluation in 0:00:01s.\n",
            "[9] Validation results:\n",
            "{\n",
            "  accuracy: \n",
            "    0.5545454545454546,\n",
            "}\n",
            "\n",
            "\n",
            "[9] Finished epoch.\n",
            "Top performing param combos:\n",
            "[((1, 1e-05, 3), 0.5288401628446416), ((1, 1e-05, 4), 0.5288401628446416), ((1, 1e-05, 5), 0.5288401628446416), ((1, 1e-05, 6), 0.5288401628446416), ((1, 1e-05, 7), 0.5288401628446416)]\n"
          ]
        }
      ]
    }
  ]
}